# Система сжатия текста с регулировкой (Часть проекта "Чат-бот для чтения книг с ИИ-ассистентом")

## Обзор проекта

Этот репозиторий содержит основные компоненты системы для сжатия текста с возможностью регулировки степени сжатия. Система разработана в рамках группового проекта для Всероссийского конкурса научно-технологических проектов "Большие вызовы". Данная система предназначена для интеграции в более крупное приложение — Telegram-бот, выступающий в роли ИИ-ассистента для чтения книг.

Основная цель этого компонента — предоставлять качественные краткие изложения (саммари) текста с настраиваемой длиной, учитывая тип исходного контента (например, литературный, научный) для сохранения ключевых идей и стиля.

**Примечание:** Этот репозиторий фокусируется на логике сжатия текста, взаимодействии с базой данных для этой системы и скриптах для её оценки. Другие компоненты чат-бота (пользовательский интерфейс, интеграция с системой анализа содержания, система рекомендаций) разрабатываются другими участниками команды.
*   **Система анализа содержания книг:** https://github.com/ArseniyNov52/System_recommedations (Автор: Коротаев Никита)
*   **Система рекомендаций книг:** https://github.com/ArseniyNov52/System_recommedations (Автор: Куликов Данил)

## Ключевые особенности

*   **Контекстно-зависимое сжатие:** Генерирует инструкции на основе типа текста (с использованием Mixtral), чтобы направлять модель сжатия.
*   **Настраиваемая длина саммари:** Позволяет пользователю указывать желаемую длину итогового краткого изложения.
*   **Интеграция RAG:** Использует Retrieval-Augmented Generation (RAG) с эмбеддингами предложений (`ai-forever/ru-en-RoSBERTa`) для предоставления релевантного контекста из всего документа модели сжатия (Llama-3-Typhoon), улучшая связность и сохранение информации для длинных текстов.
*   **Асинхронная обработка:** Применяет `asyncio` для эффективной обработки API-запросов и обработки текста, особенно для больших документов.
*   **Интеграция с базой данных:** Взаимодействует с базой данных PostgreSQL для хранения информации о книгах, состоянии чтения и сгенерированных саммари.

## Структура репозитория и описание файлов

### `chat_bot_code.py`

*   **Назначение:** Этот модуль отвечает за взаимодействие с базой данных PostgreSQL. Он содержит функции для инициализации БД, добавления и получения информации о пользователях и книгах, управления состоянием чтения (текущая страница, контекст для ИИ, история чата), а также для получения текста книг (постранично или целиком).
*   **Ключевые аспекты:**
    *   Использует `psycopg2` для работы с PostgreSQL.
    *   Создает и управляет таблицами `users`, `books`, `reading_state`, `recommendation_history`.
    *   Реализует логику для расчета "страниц" для TXT файлов и извлечения страниц из PDF (`PyPDF2`).
    *   Определяет кодировку TXT файлов с помощью `chardet`.
    *   Предусматривает хранение JSONB данных (предпочтения, история чата).
    *   Обрабатывает ошибки подключения и выполнения запросов к БД.
    *   Функции `get_book_page_content` и `get_book_full_text` извлекают текст из файлов, хранящихся локально (в директории `USER_BOOKS_BASE_DIR`).

### `compress_text_tool.py`

*   **Назначение:** Ядро системы сжатия текста. Реализует полный пайплайн: получение текста, генерация инструкций, индексация для RAG, сегментация, асинхронное сжатие сегментов с использованием RAG-контекста и объединение результатов.
*   **Ключевые аспекты:**
    *   **Генерация инструкций:** Использует модель `Mixtral` (через API) для анализа фрагмента текста и определения ключевых параметров для сжатия (`generate_instructions`).
    *   **RAG:**
        *   Разбивает текст на чанки (`chunk_for_rag`).
        *   Создает векторные представления (эмбеддинги) чанков с помощью `SentenceTransformer` (`ai-forever/ru-en-RoSBERTa`) в функции `build_rag_index`.
        *   Находит релевантные чанки для каждого сегмента текста (`retrieve_relevant_chunks`).
    *   **Сегментация:** Делит текст на смысловые сегменты для параллельной обработки (`segment_text`).
    *   **Асинхронное сжатие:** Использует `asyncio` и `HuggingFace Hub InferenceClient` (или аналогичный) для асинхронных вызовов к модели сжатия (`Llama-3-Typhoon` через Together AI API) для каждого сегмента (`summarize_segment`). Передает инструкции и RAG-контекст в промпт.
    *   **Интеграция с БД:** Вызывает функции из `chat_bot_code.py` для получения текста книги и сохранения итогового саммари (`summarize_text_and_update_db`).

### `api_local_comparison.py`

*   **Назначение:** Скрипт для сравнения производительности и качества моделей сжатия при запуске через API и локально (хотя локальный запуск в коде использует `transformers` для генерации, а не только для эмбеддингов). Сравнивает модели `Phi-3.5-mini` и `Gemma-2b`.
*   **Ключевые аспекты:**
    *   Загружает тестовый датасет (`RussianNLP/Mixed-Summarization-Dataset`).
    *   Использует `HuggingFace Hub InferenceClient` для API-вызовов.
    *   Использует `transformers` (`AutoModelForCausalLM`, `AutoTokenizer`) для локальной генерации.
    *   Оценивает модели по скорости выполнения, метрикам BERT-Score (с `ai-forever/ru-en-RoSBERTa`) и коэффициенту Жаккара.
    *   Выводит агрегированные результаты в виде таблицы.

### `models_comparison.py`

*   **Назначение:** Скрипт для сравнения качества и производительности различных *крупных* моделей сжатия, доступных через API (в данном случае, Together AI). Сравнивает `Mixtral-8x22B`, `Llama-3.1-Nemotron-70B`, `Llama-3-Typhoon-70B`.
*   **Ключевые аспекты:**
    *   Аналогичен `api_local_comparison.py`, но тестирует другие модели и только через API.
    *   Использует `HuggingFace Hub InferenceClient` с провайдером `together`.
    *   Загружает датасет (`RussianNLP/Mixed-Summarization-Dataset`).
    *   Оценивает модели по скорости, BERT-Score и коэффициенту Жаккара.
    *   Выводит сводную таблицу результатов.

### `final_testing.py`

*   **Назначение:** Скрипт для проведения итогового комплексного тестирования разработанной системы сжатия (`Llama-3-Typhoon` с генерацией инструкций и сегментацией). Оценивает систему на смешанной выборке из нескольких датасетов. Проводит два прогона: с использованием генерации инструкций и без нее.
*   **Ключевые аспекты:**
    *   Загружает несколько датасетов (`ru_dialogsum`, `Mixed-Summarization-Dataset`, `BooksSummarizationRU`, `gazeta`).
    *   Реализует упрощенные версии генерации инструкций (`generate_instructions`), сегментации (`segment_text`) и сжатия сегментов (`summarize_segment`), аналогичные `compress_text_tool.py`.
    *   Использует `HuggingFace Hub InferenceClient` (Together AI) для вызовов моделей.
    *   Оценивает результаты по метрикам: BERT-Score, коэффициент Жаккара, производительность (слов/сек), отклонение от целевой длины саммари.
    *   Проводит тесты в двух режимах (`use_instructions=True/False`).
    *   Выводит итоговые средние значения метрик для каждого режима.
